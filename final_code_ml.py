# -*- coding: utf-8 -*-
"""final_code_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uik_E1bozoY75JLjxmiU3FElK_TXrl5h
"""

# Install necessary packages
!pip install pinecone-client cohere sentence-transformers streamlit pyngrok

# Import required packages
import pinecone
import cohere
from sentence_transformers import SentenceTransformer
from pyngrok import ngrok

# Initialize Pinecone client correctly
api_key = '87a3914b-75ee-4c0c-b4cf-b294158e0747'
environment = 'us-east-1'

# Instance of the Pinecone class
pinecone_client = pinecone.Pinecone(api_key=api_key)

# Check and create an index if it doesn't exist
index_name = "qa-bot-index"

# All available indexes and create if needed
if index_name not in pinecone_client.list_indexes().names():
    pinecone_client.create_index(
        name=index_name,
        dimension=384,
        metric='cosine',
        spec=pinecone.ServerlessSpec(
            cloud='aws',
            region=environment
        )
    )

# Connected to the index
index = pinecone_client.Index(index_name)

# SentenceTransformer model for embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')

# Uploaded file
with open('/content/clean-energy-index.txt', 'r') as file:
    document_text = file.read()

# Document Splited into paragraphs
paragraphs = document_text.split('\n\n')

# Embeddings for each paragraph and upsert them into Pinecone
for i, paragraph in enumerate(paragraphs):
    if paragraph.strip():  # Skip empty paragraphs
        embedding = model.encode(paragraph).tolist()  # Convert to list
        index.upsert(vectors=[(f'paragraph_{i}', embedding, {'text': paragraph})])

# Cohere for generating answers
co = cohere.Client('omTyaHvoeFTz8JelXtrfXxdal0FFkvMVK4UDAKff')

# Function to query Pinecone for relevant paragraphs
def query_pinecone(question):
    query_embedding = model.encode(question).tolist()  # Convert to list
    result = index.query(vector=query_embedding, top_k=1, include_metadata=True)
    best_match_paragraph = result['matches'][0]['metadata']['text']
    return best_match_paragraph

# Function to generate answers using Cohere
def generate_answer(question, context):
    prompt = f"Context: {context}\nQuestion: {question}\nAnswer:"
    response = co.generate(model='command-xlarge-nightly', prompt=prompt, max_tokens=150)
    return response.generations[0].text.strip()

# Streamlit app script (app.py)
with open('app.py', 'w') as f:
    f.write('''
import streamlit as st
import pinecone
import cohere
from sentence_transformers import SentenceTransformer

# Correct initialization for Pinecone
api_key = '87a3914b-75ee-4c0c-b4cf-b294158e0747'
pinecone_client = pinecone.Pinecone(api_key=api_key)

index_name = "qa-bot-index"
index = pinecone_client.Index(index_name)

# SentenceTransformer model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Initialize Cohere
co = cohere.Client('omTyaHvoeFTz8JelXtrfXxdal0FFkvMVK4UDAKff')

st.title("Interactive Clean Energy QA Bot")

# Function to query Pinecone
def query_pinecone(question):
    query_embedding = model.encode(question).tolist()  # Convert to list
    result = index.query(vector=query_embedding, top_k=1, include_metadata=True)
    best_match_paragraph = result['matches'][0]['metadata']['text']
    return best_match_paragraph

# Function to generate an answer using Cohere
def generate_answer(question, context):
    prompt = f"Context: {context}\\nQuestion: {question}\\nAnswer:"
    response = co.generate(model='command-xlarge-nightly', prompt=prompt, max_tokens=150)
    return response.generations[0].text.strip()

# Streamlit user interaction
user_question = st.text_input("Ask a question about clean energy:")

if user_question:
    st.write("You asked:", user_question)

    # Retrieve relevant paragraph
    retrieved_paragraph = query_pinecone(user_question)
    st.write("Retrieved Paragraph:", retrieved_paragraph)

    # Generate detailed answer
    generated_answer = generate_answer(user_question, retrieved_paragraph)
    st.write("Generated Answer:", generated_answer)
    ''')

# Run the Streamlit app in the background
!streamlit run app.py &> /dev/null &

# Set up Ngrok to expose the Streamlit app
ngrok.set_auth_token("2nC5Cc0NH5B31IE9mh8DUIoFGsf_4TcVQUEWpwg11QwygusvY")

# Create a public URL to access the Streamlit app
public_url = ngrok.connect(addr="8501")
print(f'Public URL: {public_url}')